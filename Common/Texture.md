#drawing #rendering 

Texture refers to the surface characteristics of an object that are applied to its visual representation. Textures are used to add detail, realism, and complexity to computer-generated images. These surface characteristics include properties such as color, roughness, reflectivity, transparency, and pattern.

Textures are typically represented as 2D images, known as texture maps, which are applied to the surface of 3D models. These texture maps can be created manually by artists or generated procedurally using algorithms.

Texture can also be 1D (e.g. color palette) or 3D (e.g. noise volume texture).

Some common types of texture maps include:

1. **Color Map (Diffuse Map)**: This texture defines the base color of the surface.
2. **Normal Map**: A normal map encodes surface normal information to simulate finer surface details, such as bumps and wrinkles, without adding additional geometry.
3. **Specular Map**: Specifies the intensity of specular highlights on the surface.
4. **Roughness Map**: Controls the smoothness or roughness of the surface.
5. **Bump Map**: Similar to a normal map, it simulates surface details by perturbing the surface normals.
6. **Opacity Map**: Defines which parts of the surface are transparent or opaque.
7. **Displacement Map**: Displaces the surface geometry to create detailed surface features.

These texture maps are applied using various mapping techniques such as UV mapping, which involves unwrapping the 3D model into a 2D plane to accurately apply the textures.

### Applying texture to a model

Suppose we have a triangle. In order to apply (map) a texture to it, we need to specify for each vertex which part of a texture it corresponds to. Each vertex must have **texture coordinates** that specify what part of a texture to sample from. Fragment interpolation handles the valid color assignment for each fragment.

Each texture coordinate lies in a range of \[0, 1\] along x and y axes. Retrieving texture color using texture coordinates is called **sampling**. 

Texture coordinates system looks like this:

![[Texcoords.png]]

Note that X axis is named `U` (or `s`) and y axis is named `V` (or `t`). Z axis is named `W` (or `r`). So, the set of texture axes can be named as `UV`, `UVW`, `st` or `str`.
___
### OpenGL

#### Texture filtering

Texcoords do not depend on the texture resolution and can be any float value. OpenGL needs to figure out which texture pixel (**texel**) to map the texcoord to. This can be critical when applying low-res texture to a huge model. 

In OpenGL, there are several options available for **texture filtering**.

##### GL_NEAREST

Default filtering mode, also known as *Point filtering*. OpenGL selects the texel which center is the closest to the given texcoord.

**Example**

*For a given texcoord ~(0.45, 0.55), in a texture with 4 texels, the top-left texel is selected as its center is the closest to the given texcoord.* 

![[Point_filtering.png]]

Applying to the real texture:

![[Point_filtering2.png]]

##### GL_LINEAR

Also know as *(bi)linear filtering*. Takes an interpolated value from the texcoord neighboring texels, approximating sampled color between them. The smaller the distance to a texel center, the more that texel contributes to the sampled color.

![[Linear_filtering.png]]

Applying to the real texture:

![[Linear_filtering2.png]]

___
### Mipmaps

Mipmap is a collection of textures where each subsequent texture is twice as small compared to the previous one. 

The use-case of mipmaps can be defined as: after a certain distance from the viewer, different mipmap texture (**level**) will be used that suits the distance to the object the best. If object is located far away from the view and takes only few fragments, applying full-resolution texture would be inefficient in memory aspect, moreover, it will produce visible artifacts on the object, as it would be hard to filter the high-res texture on an extremely small object. The bigger distance is, the smaller mipmap texture will be used.

Mipmap example:

![[Mipmap.png]]

### OpenGL

In OpenGL, mipmaps can be generated by the API using [[glGenerateMipmap]] function after texture is created.

When switching between mipmaps in OpenGL, some artifacts may appear on the texture (e.g. sharp edges). It is also possible to filter between mipmap levels using next options:
- `GL_NEAREST_MIPMAP_NEAREST` - takes nearest mipmap level to match the pixel size and applies point filtering.
- `GL_LINEAR_MIPMAP_NEAREST` - takes nearest mipmap level and applies linear filtering.
- `GL_NEAREST_MIPMAP_LINEAR` - linearly interpolates between two mipmap levels that most closely match the pixel size and applies point filtering.
- `GL_LINEAR_MIPMAP_LINEAR` - interpolates between mipmap levels and applies linear filtering.

#### Texture units

Using `glUniform1i` we can assign a *location* value to the texture sampler so the fragment shader can receive multiple textures at once. This location of a texture is named **texture unit**. 

The default texture unit for a texture is 0 which is the default active texture unit. **NB!** Not all drivers assign the default texture unit.